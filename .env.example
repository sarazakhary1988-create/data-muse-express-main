# ========================================
# MANUS 1.6 MAX - Environment Template
# Copy to .env and fill in your keys
# ========================================

# ========================================
# ANTHROPIC CLAUDE (PRIMARY)
# ========================================
# Get your API key from: https://console.anthropic.com
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key

# ========================================
# OPENAI (PRIMARY)
# ========================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key

# ========================================
# GOOGLE GEMINI (SECONDARY)
# ========================================
# Get your API key from: https://aistudio.google.com
# Leave empty to skip Google
GOOGLE_API_KEY=your-google-api-key
GOOGLE_AI_STUDIO_API_KEY=your-google-ai-studio-key

# ========================================
# META LLAMA (SECONDARY - via Together AI)
# ========================================
# Get your API key from: https://www.together.ai
# Leave empty to skip Llama
TOGETHER_API_KEY=your-together-api-key-here
TOGETHER_API_ENDPOINT=https://api.together.xyz/v1

# ========================================
# ALIBABA QWEN (SECONDARY)
# ========================================
# Get your API key from: https://dashscope.aliyuncs.com
# Leave empty to skip Qwen
QWEN_API_KEY=your-qwen-api-key-here
QWEN_API_ENDPOINT=https://dashscope.aliyuncs.com/api/v1

# ========================================
# LOCAL MODELS (FALLBACK - Ollama)
# ========================================
# Set Ollama endpoint if running locally
OLLAMA_ENDPOINT=http://localhost:11434

# ========================================
# SUPABASE CONFIGURATION
# ========================================
# Create project at: https://supabase.com
# Get keys from project settings
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-supabase-anon-key-here
SUPABASE_SERVICE_ROLE_KEY=your-supabase-service-role-key-here
SUPABASE_DB_PASSWORD=your-database-password

# ========================================
# LOCAL LLM INFERENCE (OPTIONAL)
# ========================================
# Install Ollama: https://ollama.ai
# Then: ollama serve
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=deepseek-v3

# ========================================
# VECTOR DATABASE
# ========================================
# Choose one: chroma, weaviate, or qdrant
VECTOR_DB_PROVIDER=chroma
VECTOR_DB_ENDPOINT=http://localhost:8000
VECTOR_DB_API_KEY=

# ========================================
# CODE EXECUTION SANDBOXES
# ========================================
# These are optional - code execution will work with local implementations
PYTHON_SANDBOX_URL=http://localhost:8081
BASH_SANDBOX_URL=http://localhost:8082

# ========================================
# SYSTEM CONFIGURATION
# ========================================
NODE_ENV=production
PORT=3000
LOG_LEVEL=info

# ========================================
# WEBSOCKET CONFIGURATION
# ========================================
WEBSOCKET_URL=ws://localhost:3000
SOCKET_IO_CORS=*

# ========================================
# API CONFIGURATION
# ========================================
API_RATE_LIMIT=100
API_TIMEOUT=30000

# ========================================
# FEATURES CONFIGURATION
# ========================================
# Enable/disable features
ENABLE_LOCAL_LLM=true
ENABLE_CODE_EXECUTION=true
ENABLE_WEB_SCRAPING=true
ENABLE_NEWS_INTEGRATION=true
ENABLE_VECTOR_SEARCH=true

# ========================================
# DEPLOYMENT CONFIGURATION
# ========================================
# GitHub
GITHUB_TOKEN=ghp_your-github-personal-access-token
GITHUB_REPO=your-username/your-repo

# Netlify (optional for frontend deployment)
NETLIFY_AUTH_TOKEN=your-netlify-auth-token
NETLIFY_SITE_ID=your-netlify-site-id
